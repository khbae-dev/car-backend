import json
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import pickle
import glob
import os

# ğŸ“‚ ìµœì‹  JSON íŒŒì¼ íƒìƒ‰ í•¨ìˆ˜
def find_latest_json(directory='/shared-data'):
    json_files = glob.glob(os.path.join(directory, '*.json'))
    if not json_files:
        raise FileNotFoundError("âŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    latest_file = max(json_files, key=os.path.getctime)
    print(f"âœ… ìµœì‹  JSON íŒŒì¼: {latest_file}")
    return latest_file

# ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¸ë±ìŠ¤ ìƒì„± í•¨ìˆ˜
def create_faiss_index():
    # ìµœì‹  JSON íŒŒì¼ ë¡œë“œ
    latest_json = find_latest_json()
    with open(latest_json, 'r', encoding='utf-8') as f:
        car_data = json.load(f)

    # ëª¨ë¸ ë¡œë“œ
    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

    # ì°¨ëŸ‰ ë°ì´í„°ë¥¼ ì„ë² ë”©
    car_titles = [car['title'] for car in car_data]
    embeddings = model.encode(car_titles)

    # FAISS ì¸ë±ìŠ¤ ìƒì„±
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(np.array(embeddings))

    # ì¸ë±ìŠ¤ ì €ì¥
    faiss.write_index(index, 'car_faiss_index.idx')
    print("âœ… FAISS ì¸ë±ìŠ¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ë©”íƒ€ë°ì´í„° ì €ì¥
    with open('car_metadata.pkl', 'wb') as f:
        pickle.dump(car_data, f)
    print("âœ… ë©”íƒ€ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    create_faiss_index()